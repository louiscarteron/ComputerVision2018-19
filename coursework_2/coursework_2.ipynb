{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 2: Neural Networks \n",
    "\n",
    "This coursework covers the topics covered in class regarding neural networks for image classification.\n",
    "\n",
    "This coursework includes both coding questions as well as written ones. Please upload the notebook, which contains your code, results and answers as a pdf file onto Cate.\n",
    "\n",
    "Dependencies: If you work on a college computer in the Computing Lab, where Ubuntu 18.04 is installed by default, you can use the following virtual environment for your work, where relevant Python packages are already installed.\n",
    "\n",
    "`source /vol/bitbucket/wbai/virt/computer_vision_ubuntu18.04/bin/activate`\n",
    "\n",
    "Alternatively, you can use pip, pip3 or anaconda etc to install Python packages.\n",
    "\n",
    "**Note 1:** please read the both the text and code comment in this notebook to get an idea what you are supposed to implement.\n",
    "\n",
    "**Note 2:** If you are using the virtual environment in the Computing Lab, please run the following command in the command line before opening jupyter-notebook and importing tensorflow. This will tell tensorflow where the Nvidia CUDA libariries are.\n",
    "\n",
    "`export LD_LIBRARY_PATH=/vol/cuda/9.0.176/lib64/:\"${LD_LIBRARY_PATH}}\"` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation \n",
    "import collections\n",
    "import itertools\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (20 points)\n",
    "\n",
    "Throughout this coursework you will be working with the Fashion-MNIST dataset. If you are interested, you may find relevant information regarding the dataset in this paper.\n",
    "\n",
    "[1] Fashion-MNIST: A novel image dataset for benchmarking machine learning algorithms. Han Xiao, Kashif Rasul, Roland Vollgraf. [arXiv:1708.07747](https://arxiv.org/abs/1708.07747)\n",
    "\n",
    "Be sure that you have the following files in your working directory: data.tar.gz and reader.py. Loading the data can be done as follows:\n",
    "\n",
    "`from reader import get_images\n",
    "(x_train, y_train), (x_test, y_test) = get_images()`\n",
    "\n",
    "The dataset is already split into a set of 60,000 training images and a set of 10,000 test images. The images are of size 28x28 pixels and stored as 784-D vector. So if you would like to visualise the images, you need to reshape the array.\n",
    "\n",
    "There are in total 10 label classes, which are:\n",
    "* 0: T-shirt/top\n",
    "* 1: Trousers\n",
    "* 2: Pullover\n",
    "* 3: Dress\n",
    "* 4: Coat\n",
    "* 5: Sandal\n",
    "* 6: Shirt\n",
    "* 7: Sneaker\n",
    "* 8: Bag\n",
    "* 9: Ankle boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load data (6 points)\n",
    "Load the dataset and print the dimensions of the training set and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the training set is (60000, 784) with 60000 labels\n",
      "Dimensions of the test set is (10000, 784) with 10000 labels\n"
     ]
    }
   ],
   "source": [
    "from reader import get_images\n",
    "(x_train, y_train), (x_test, y_test) = get_images()\n",
    "print (\"Dimensions of the training set is %s with %s labels\" % (str(x_train.shape), str(y_train.shape[0])))\n",
    "print (\"Dimensions of the test set is %s with %s labels\" % (str(x_test.shape), str(y_test.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Visualize data (6 points)\n",
    "Visualise 3 training images (T-shirt, trousers and pullover) and 3 test images (dress, coat and sandal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = {0 : \"T-shirt/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\",\n",
    "          5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle Boot\"}\n",
    "\n",
    "# https://www.kaggle.com/gpreda/cnn-with-tensorflow-keras-for-fashion-mnist#\n",
    "\n",
    "f, ax = plt.subplots(2, 3, figsize=(8, 8))\n",
    "# 1, 5, 16 for train\n",
    "# 6, 8, 13 for test\n",
    "train_index = set([1, 5, 16])\n",
    "test_index = set([6, 8, 13])\n",
    "ite = set([0, 1, 2])\n",
    "for i, j, k in zip(ite, train_index, test_index):\n",
    "    ax[0, i].imshow(x_train[j].reshape(28, 28), cmap=\"Blues\")\n",
    "    ax[0, i].axis('off')\n",
    "    ax[0, i].set_title(labels[y_train[j]])\n",
    "    \n",
    "    ax[1, i].imshow(x_test[k].reshape(28, 28), cmap=\"Greens\")\n",
    "    ax[1, i].axis('off')\n",
    "    ax[1, i].set_title(labels[y_test[k]])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data balance (4 points)\n",
    "Print out the number of training samples for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ankle Boot          :   6000 or 10.0%\n",
      "T-shirt/top         :   6000 or 10.0%\n",
      "Dress               :   6000 or 10.0%\n",
      "Pullover            :   6000 or 10.0%\n",
      "Sneaker             :   6000 or 10.0%\n",
      "Sandal              :   6000 or 10.0%\n",
      "Trouser             :   6000 or 10.0%\n",
      "Shirt               :   6000 or 10.0%\n",
      "Coat                :   6000 or 10.0%\n",
      "Bag                 :   6000 or 10.0%\n"
     ]
    }
   ],
   "source": [
    "labels = {0 : \"T-shirt/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\",\n",
    "          5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle Boot\"}\n",
    "\n",
    "def get_classes_distribution(data):\n",
    "    # Get the count for each label\n",
    "    label_counts = collections.Counter(data)\n",
    "\n",
    "    # Get total number of samples\n",
    "    total_samples = len(data)\n",
    "    \n",
    "    samp_values = list(label_counts.values())\n",
    "    samp_keys = list(label_counts.keys())\n",
    "\n",
    "    # Count the number of items in each class\n",
    "    for i in range(len(label_counts)):\n",
    "        label = labels[samp_keys[i]]\n",
    "        count = samp_values[i]\n",
    "        percent = (count / total_samples) * 100\n",
    "        print(\"{:<20s}:   {} or {}%\".format(label, count, percent))\n",
    "\n",
    "get_classes_distribution(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Discussion (4 points)\n",
    "Is the dataset balanced? What would happen if the dataset is not balanced in the context of image classification? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is balanced, as each category is represented by 10%. If the dataset is not balanced, then the set will be biased towards a certain image classification. This would mean that it would favor the output of a certain label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (40 points)\n",
    "\n",
    "Build a neural network and train it with the Fashion-MNIST dataset. Here, we use the keras library, which is a high-level neural network library built upon tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the label class into a one-hot representation\n",
    "# 10 for the number of labels.\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Build a multi-layer perceptron, also known as multi-layer fully connected network. You need to define the layers, the loss function, the optimiser and evaluation metric. (30 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 150)               75150     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1510      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,084,600\n",
      "Trainable params: 1,084,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(Dense(784, input_dim=784))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(500))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(150))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "#model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Define the optimisation parameters including the batch size and the number of epochs and then run the optimiser. (10 points)\n",
    "\n",
    "We have tested that for an appropriate network architecture, on a personal laptop and with only CPU, it takes about a few seconds per epoch to train the network. For 100 epochs, it takes about a coffee break's time to finish the training. If you run it on a powerful GPU, it would be even much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 11.0223 - acc: 0.3101\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 8.7543 - acc: 0.4502\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 7.6842 - acc: 0.5148\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 6.4149 - acc: 0.5920\n",
      "Epoch 5/100\n",
      "27000/60000 [============>.................] - ETA: 1s - loss: 5.9717 - acc: 0.6204"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-db03a6395247>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/vol/bitbucket/wbai/virt/computer_vision_ubuntu18.04/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/vol/bitbucket/wbai/virt/computer_vision_ubuntu18.04/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/bitbucket/wbai/virt/computer_vision_ubuntu18.04/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/bitbucket/wbai/virt/computer_vision_ubuntu18.04/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/bitbucket/wbai/virt/computer_vision_ubuntu18.04/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "epochs = 100\n",
    "model.fit(x = x_train, y = y_train, batch_size = batch_size, epochs = epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (20 points) \n",
    "\n",
    "Evaluate the performance of your network with the test data. \n",
    "Visualize the performance using appropriate metrics and graphs (eg. confusion matrix). \n",
    "Comment on your per class performance and how it could be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is provided for you to display the confusion matrix.\n",
    "# For more information about the confusion matrix, you can read at\n",
    "# https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "        This function prints and plots the confusion matrix.\n",
    "        \n",
    "        cm: confusion matrix, default to be np.int32 data type\n",
    "        classes: a list of the class labels or class names\n",
    "        normalize: normalize the matrix so that each row amounts to one\n",
    "        cmap: color map\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    cm = cm.astype(int)\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Evaluate the classification accuracy on the test set (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, metric = model.evaluate(x = x_test, y = y_test)\n",
    "print(loss)\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Calculate and plot the confusion matrix (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "matrix = np.zeros((10, 10))\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    maxp = np.argmax(predictions[i])\n",
    "    actual = np.argmax(y_test[i])\n",
    "    matrix[maxp][actual] += 1\n",
    "    \n",
    "plot_confusion_matrix(matrix, list(labels.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (20 points)\n",
    "Take two photos, one of your clothes or shoes that belongs to one of 10 classes, the other that does not belong to any class.\n",
    "\n",
    "Use either Python or other software (Photoshop, Gimp, or any image editer) to convert the photos into grayscale, crop the region of interest and reshape into the size of 28x28.\n",
    "\n",
    "### 4.1 Load and visualise your own images (6 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "airforce = tf.image.decode_jpeg(tf.read_file('airforce.jpg'))\n",
    "rayban = tf.image.decode_jpeg(tf.read_file('rayban.jpg'))\n",
    "resized_airforce = tf.image.resize_images(airforce, [28, 28])\n",
    "resized_rayban = tf.image.resize_images(rayban, [28, 28])\n",
    "gray_airforce = tf.image.rgb_to_grayscale(resized_airforce)\n",
    "gray_rayban = tf.image.rgb_to_grayscale(resized_rayban)\n",
    "\n",
    "atf = tf.Variable(gray_airforce)\n",
    "rtf = tf.Variable(gray_rayban)\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "ima = sess.run(atf)\n",
    "ima.resize((28, 28))\n",
    "imr = sess.run(rtf)\n",
    "imr.resize((28, 28))\n",
    "fig = plt.figure()\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.imshow(ima, cmap=\"gray\")\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.imshow(imr, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Test your network on the two images and show the classification results (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Discuss the classification results and provide one method to improve real life performance of the network (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Survey\n",
    "How long did the coursework take you to solve? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
