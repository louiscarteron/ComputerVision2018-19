{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 2: Neural Networks \n",
    "\n",
    "This coursework covers the topics covered in class regarding neural networks for image classification.\n",
    "\n",
    "This coursework includes both coding questions as well as written ones. Please upload the notebook, which contains your code, results and answers as a pdf file onto Cate.\n",
    "\n",
    "Dependencies: If you work on a college computer in the Computing Lab, where Ubuntu 18.04 is installed by default, you can use the following virtual environment for your work, where relevant Python packages are already installed.\n",
    "\n",
    "`source /vol/bitbucket/wbai/virt/computer_vision_ubuntu18.04/bin/activate`\n",
    "\n",
    "Alternatively, you can use pip, pip3 or anaconda etc to install Python packages.\n",
    "\n",
    "**Note 1:** please read the both the text and code comment in this notebook to get an idea what you are supposed to implement.\n",
    "\n",
    "**Note 2:** If you are using the virtual environment in the Computing Lab, please run the following command in the command line before opening jupyter-notebook and importing tensorflow. This will tell tensorflow where the Nvidia CUDA libariries are.\n",
    "\n",
    "`export LD_LIBRARY_PATH=/vol/cuda/9.0.176/lib64/:\"${LD_LIBRARY_PATH}}\"` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation \n",
    "import collections\n",
    "import itertools\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (20 points)\n",
    "\n",
    "Throughout this coursework you will be working with the Fashion-MNIST dataset. If you are interested, you may find relevant information regarding the dataset in this paper.\n",
    "\n",
    "[1] Fashion-MNIST: A novel image dataset for benchmarking machine learning algorithms. Han Xiao, Kashif Rasul, Roland Vollgraf. [arXiv:1708.07747](https://arxiv.org/abs/1708.07747)\n",
    "\n",
    "Be sure that you have the following files in your working directory: data.tar.gz and reader.py. Loading the data can be done as follows:\n",
    "\n",
    "`from reader import get_images\n",
    "(x_train, y_train), (x_test, y_test) = get_images()`\n",
    "\n",
    "The dataset is already split into a set of 60,000 training images and a set of 10,000 test images. The images are of size 28x28 pixels and stored as 784-D vector. So if you would like to visualise the images, you need to reshape the array.\n",
    "\n",
    "There are in total 10 label classes, which are:\n",
    "* 0: T-shirt/top\n",
    "* 1: Trousers\n",
    "* 2: Pullover\n",
    "* 3: Dress\n",
    "* 4: Coat\n",
    "* 5: Sandal\n",
    "* 6: Shirt\n",
    "* 7: Sneaker\n",
    "* 8: Bag\n",
    "* 9: Ankle boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load data (6 points)\n",
    "Load the dataset and print the dimensions of the training set and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the training set is (60000, 784) with 60000 labels\n",
      "Dimensions of the test set is (10000, 784) with 10000 labels\n"
     ]
    }
   ],
   "source": [
    "from reader import get_images\n",
    "(x_train, y_train), (x_test, y_test) = get_images()\n",
    "print (\"Dimensions of the training set is %s with %s labels\" % (str(x_train.shape), str(y_train.shape[0])))\n",
    "print (\"Dimensions of the test set is %s with %s labels\" % (str(x_test.shape), str(y_test.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Visualize data (6 points)\n",
    "Visualise 3 training images (T-shirt, trousers and pullover) and 3 test images (dress, coat and sandal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = {0 : \"T-shirt/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\",\n",
    "          5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle Boot\"}\n",
    "\n",
    "# https://www.kaggle.com/gpreda/cnn-with-tensorflow-keras-for-fashion-mnist#\n",
    "\n",
    "f, ax = plt.subplots(2, 3, figsize=(8, 8))\n",
    "# 1, 5, 16 for train\n",
    "# 6, 8, 13 for test\n",
    "train_index = set([1, 5, 16])\n",
    "test_index = set([6, 8, 13])\n",
    "ite = set([0, 1, 2])\n",
    "for i, j, k in zip(ite, train_index, test_index):\n",
    "    ax[0, i].imshow(x_train[j].reshape(28, 28), cmap=\"Blues\")\n",
    "    ax[0, i].axis('off')\n",
    "    ax[0, i].set_title(labels[y_train[j]])\n",
    "    \n",
    "    ax[1, i].imshow(x_test[k].reshape(28, 28), cmap=\"Greens\")\n",
    "    ax[1, i].axis('off')\n",
    "    ax[1, i].set_title(labels[y_test[k]])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data balance (4 points)\n",
    "Print out the number of training samples for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ankle Boot          :   6000 or 10.0%\n",
      "T-shirt/top         :   6000 or 10.0%\n",
      "Dress               :   6000 or 10.0%\n",
      "Pullover            :   6000 or 10.0%\n",
      "Sneaker             :   6000 or 10.0%\n",
      "Sandal              :   6000 or 10.0%\n",
      "Trouser             :   6000 or 10.0%\n",
      "Shirt               :   6000 or 10.0%\n",
      "Coat                :   6000 or 10.0%\n",
      "Bag                 :   6000 or 10.0%\n"
     ]
    }
   ],
   "source": [
    "labels = {0 : \"T-shirt/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\",\n",
    "          5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle Boot\"}\n",
    "\n",
    "def get_classes_distribution(data):\n",
    "    # Get the count for each label\n",
    "    label_counts = collections.Counter(data)\n",
    "\n",
    "    # Get total number of samples\n",
    "    total_samples = len(data)\n",
    "    \n",
    "    samp_values = list(label_counts.values())\n",
    "    samp_keys = list(label_counts.keys())\n",
    "\n",
    "    # Count the number of items in each class\n",
    "    for i in range(len(label_counts)):\n",
    "        label = labels[samp_keys[i]]\n",
    "        count = samp_values[i]\n",
    "        percent = (count / total_samples) * 100\n",
    "        print(\"{:<20s}:   {} or {}%\".format(label, count, percent))\n",
    "\n",
    "get_classes_distribution(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Discussion (4 points)\n",
    "Is the dataset balanced? What would happen if the dataset is not balanced in the context of image classification? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is balanced, as each category is represented by 10%. If the dataset is not balanced, then the set will be biased towards a certain image classification. This would mean that it would favor the output of a certain label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (40 points)\n",
    "\n",
    "Build a neural network and train it with the Fashion-MNIST dataset. Here, we use the keras library, which is a high-level neural network library built upon tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the label class into a one-hot representation\n",
    "# 10 for the number of labels.\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Build a multi-layer perceptron, also known as multi-layer fully connected network. You need to define the layers, the loss function, the optimiser and evaluation metric. (30 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 150)               75150     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                1510      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,084,600\n",
      "Trainable params: 1,084,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(Dense(784, input_dim=784))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(500))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(150))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "#model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Define the optimisation parameters including the batch size and the number of epochs and then run the optimiser. (10 points)\n",
    "\n",
    "We have tested that for an appropriate network architecture, on a personal laptop and with only CPU, it takes about a few seconds per epoch to train the network. For 100 epochs, it takes about a coffee break's time to finish the training. If you run it on a powerful GPU, it would be even much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 11.8887 - acc: 0.2605\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 9.6994 - acc: 0.3954\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 8.6862 - acc: 0.4587\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 8.5278 - acc: 0.4686\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 7.8528 - acc: 0.5077\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 7.1770 - acc: 0.5494\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 6.7745 - acc: 0.5739\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 6.6201 - acc: 0.5843\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 6.5019 - acc: 0.5921\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 6.3200 - acc: 0.6035\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 6.2870 - acc: 0.6048\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 6.1998 - acc: 0.6105\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 6.1412 - acc: 0.6136\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 5.5784 - acc: 0.6464\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 4.6920 - acc: 0.7015\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 4.6097 - acc: 0.7044\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 4.4922 - acc: 0.7082\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 4.0062 - acc: 0.7132\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 2.4311 - acc: 0.7049\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.8818 - acc: 0.7644\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.6952 - acc: 0.7798\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.6239 - acc: 0.7953\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.5884 - acc: 0.8032\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.5631 - acc: 0.8077\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.5372 - acc: 0.8133\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.5308 - acc: 0.8160\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.5115 - acc: 0.8212\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.4989 - acc: 0.8248\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.4956 - acc: 0.8243\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.4811 - acc: 0.8290\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.4770 - acc: 0.8303\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.4674 - acc: 0.8338\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.4625 - acc: 0.8359\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.4554 - acc: 0.8371\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.4480 - acc: 0.8394\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.4437 - acc: 0.8385\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.4400 - acc: 0.8407\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.4357 - acc: 0.8416\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.4306 - acc: 0.8438\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.4237 - acc: 0.8456\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.4210 - acc: 0.8476\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.4218 - acc: 0.8475\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.4156 - acc: 0.8499\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.4135 - acc: 0.8511\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.4092 - acc: 0.8514: 2\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.4081 - acc: 0.8498\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.4055 - acc: 0.8517: 1s - l\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.4021 - acc: 0.8537\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.4000 - acc: 0.8533: 0s - loss: 0.3979 \n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3959 - acc: 0.8559\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3957 - acc: 0.8573\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3921 - acc: 0.8559\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3903 - acc: 0.8582\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.3884 - acc: 0.8578\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.3825 - acc: 0.8602\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3820 - acc: 0.8585\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3817 - acc: 0.8604\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.3752 - acc: 0.8615\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3711 - acc: 0.8634\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3724 - acc: 0.8643\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.3720 - acc: 0.8626\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3743 - acc: 0.8640\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3695 - acc: 0.8648\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.3665 - acc: 0.8644\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3645 - acc: 0.8645\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3632 - acc: 0.8651\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3607 - acc: 0.8669\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.3615 - acc: 0.8655\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.3574 - acc: 0.8682\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3598 - acc: 0.8681\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3554 - acc: 0.8683\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3525 - acc: 0.8689\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3532 - acc: 0.8694\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3515 - acc: 0.8699\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3480 - acc: 0.8716\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3476 - acc: 0.8701\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3451 - acc: 0.8713\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3423 - acc: 0.8730\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3450 - acc: 0.8726\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3411 - acc: 0.8735\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3400 - acc: 0.8723\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3385 - acc: 0.8738\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3403 - acc: 0.8733\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3334 - acc: 0.8760\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3361 - acc: 0.8750\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3355 - acc: 0.8765\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3306 - acc: 0.8759\n",
      "Epoch 88/100\n",
      "44000/60000 [=====================>........] - ETA: 0s - loss: 0.3335 - acc: 0.8750"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "epochs = 100\n",
    "model.fit(x = x_train, y = y_train, batch_size = batch_size, epochs = epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (20 points) \n",
    "\n",
    "Evaluate the performance of your network with the test data. \n",
    "Visualize the performance using appropriate metrics and graphs (eg. confusion matrix). \n",
    "Comment on your per class performance and how it could be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is provided for you to display the confusion matrix.\n",
    "# For more information about the confusion matrix, you can read at\n",
    "# https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "        This function prints and plots the confusion matrix.\n",
    "        \n",
    "        cm: confusion matrix, default to be np.int32 data type\n",
    "        classes: a list of the class labels or class names\n",
    "        normalize: normalize the matrix so that each row amounts to one\n",
    "        cmap: color map\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    cm = cm.astype(int)\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Evaluate the classification accuracy on the test set (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, metric = model.evaluate(x = x_test, y = y_test)\n",
    "print(loss)\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Calculate and plot the confusion matrix (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "matrix = np.zeros((10, 10))\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    maxp = np.argmax(predictions[i])\n",
    "    actual = np.argmax(y_test[i])\n",
    "    matrix[maxp][actual] += 1\n",
    "    \n",
    "plot_confusion_matrix(matrix, list(labels.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (20 points)\n",
    "Take two photos, one of your clothes or shoes that belongs to one of 10 classes, the other that does not belong to any class.\n",
    "\n",
    "Use either Python or other software (Photoshop, Gimp, or any image editer) to convert the photos into grayscale, crop the region of interest and reshape into the size of 28x28.\n",
    "\n",
    "### 4.1 Load and visualise your own images (6 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#airforce = tf.image.decode_jpeg('airforce.jpg')\n",
    "#rayban = tf.image.decode_jpeg('rayban.jpg')\n",
    "#resized_airforce = tf.image.resize_images(airforce, [28, 28])\n",
    "#resized_rayban = tf.image.resize_images(rayban, [28, 28])\n",
    "#gray_airforce = tf.image.rgb_to_grayscale(resized_airforce)\n",
    "#gray_rayban = tf.image.rgb_to_grayscale(resized_rayban)\n",
    "\n",
    "#sess = tf.InteractiveSession()\n",
    "#gray_airforce.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Test your network on the two images and show the classification results (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Discuss the classification results and provide one method to improve real life performance of the network (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Survey\n",
    "How long did the coursework take you to solve? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
